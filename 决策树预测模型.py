# =============== æ•°æ®é¢„å¤„ç†éƒ¨åˆ† ===============
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from collections import Counter
import math

data = pd.read_csv(r"E:\72h\diabetes.csv")

# å¤„ç†0å€¼
cols_to_clean = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
data[cols_to_clean] = data[cols_to_clean].replace(0, np.nan)

# å¡«å……ç¼ºå¤±å€¼
data.fillna(data.mean(), inplace=True)

# åˆ é™¤é‡å¤å€¼
data.drop_duplicates(inplace=True)
# =============== æ•°æ®æ‹†åˆ† ===============
X = data.drop('Outcome', axis=1)
y = data['Outcome']

# å…ˆæ‹†åˆ†å†ç¼©æ”¾ï¼ˆé˜²æ­¢æ•°æ®æ³„éœ²ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
# ç‰¹å¾ç¼©æ”¾
# =============== ç‰¹å¾ç¼©æ”¾ ===============
scaler = MinMaxScaler()
X_train[cols_to_clean] = scaler.fit_transform(X_train[cols_to_clean])
X_test[cols_to_clean] = scaler.transform(X_test[cols_to_clean])
# =============== æ¨¡å‹è®­ç»ƒéƒ¨åˆ† ===============
X = data.drop('Outcome', axis=1)
y = data['Outcome']
# åˆ›å»ºæ¨¡å‹
model = RandomForestClassifier(
    n_estimators=100,
    max_features=int(math.sqrt(len(X.columns))),
    random_state=42
)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(f"\nğŸ¯ æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{accuracy_score(y_test, y_pred)*100:.1f}%")
# è®­ç»ƒæ¨¡å‹

# =============== é¢„æµ‹å±•ç¤ºéƒ¨åˆ† ===============
print("è¯·è¾“å…¥ä»¥ä¸‹ä¿¡æ¯æ¥è¿›è¡Œç³–å°¿ç—…é¢„æµ‹ï¼š")
# å®šä¹‰è·å–æµ®ç‚¹æ•°è¾“å…¥çš„å‡½æ•°
def get_float_input(prompt):
    while True:
        try:
            value = float(input(prompt))
            return value
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ•°å­—ã€‚")

pregnancies = int(get_float_input("æ€€å­•æ¬¡æ•°ï¼š"))
def validate_glucose(value):
    if value < 20 or value > 300:  # è¡€ç³–åˆç†èŒƒå›´
        raise ValueError("è¡€ç³–å€¼åº”åœ¨20-300ä¹‹é—´")
    return value

glucose = validate_glucose(get_float_input("è¡€ç³–ï¼š"))
blood_pressure = get_float_input("è¡€å‹ï¼š")
skin_thickness = get_float_input("çš®è‚¤åšåº¦ï¼š")
insulin = get_float_input("èƒ°å²›ç´ ï¼š")
bmi = get_float_input("BMIï¼š")
diabetes_pedigree = get_float_input("ç³–å°¿ç—…é—ä¼ å‡½æ•°ï¼š")
age = int(get_float_input("å¹´é¾„ï¼š"))

# å°†è¾“å…¥çš„æ•°æ®æ•´ç†æˆæ¨¡å‹éœ€è¦çš„æ ¼å¼
new_data = [[pregnancies, glucose, blood_pressure, skin_thickness, insulin, bmi, diabetes_pedigree, age]]
new_data_df = pd.DataFrame(new_data, columns=data.columns[:-1])


# ç¼©æ”¾æ–°æ•°æ®
new_data_df[cols_to_clean] = scaler.transform(new_data_df[cols_to_clean])
# è¿›è¡Œé¢„æµ‹
prediction = model.predict(new_data_df)  # æ³¨æ„ç”¨å›modelè€Œä¸æ˜¯tree
probability = model.predict_proba(new_data_df)[0][1]  # è·å–æ‚£ç—…æ¦‚ç‡

# è¾“å‡ºæ¯æ£µæ ‘çš„é¢„æµ‹ç»“æœ
tree_predictions = []
for i, tree in enumerate(model.estimators_, 1):
    pred = tree.predict(new_data_df.values)
    tree_predictions.append(pred[0])
    print(f"ğŸŒ³ ç¬¬{i}ä½æ ‘ç²¾çµçš„ä½è¯­ â†’ {'âš ï¸æœ‰é£é™©' if pred[0]==1 else 'ğŸƒå®‰å…¨'}")

# ç»Ÿè®¡æ‰€æœ‰æ ‘çš„é¢„æµ‹ç»“æœ
final_vote = Counter(tree_predictions).most_common(1)[0][0]

# è¾“å‡ºæœ€ç»ˆé¢„æµ‹ç»“æœ
print(f"\nğŸŒ¸ æ£®æ—çš„æ¸©æŸ”è£å†³ï¼š")
print(f"ğŸ’– æ‚£ç—…æ¦‚ç‡: {probability*100:.1f}%")
print("â¤ï¸ğŸ©¹ å»ºè®®ï¼š" + ("è¯·åŠæ—¶å°±åŒ»æ£€æŸ¥ï¼" if prediction[0]==1 else "ç»§ç»­ä¿æŒå¥åº·ä½œæ¯ï½"))
# =============== ç»Ÿä¸€æ‰“å°ç‰¹å¾é‡è¦æ€§ ===============
print(f"\nğŸŒ³ æ¯æ£µæ ‘ä½¿ç”¨ç‰¹å¾æ•°ï¼š{model.max_features}")
importance = pd.Series(model.feature_importances_, index=X.columns)
print("\nğŸŒŸ ç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œï¼š")
print(importance.sort_values(ascending=False).to_string())